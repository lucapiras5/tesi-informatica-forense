## Problemi dell'informatica forense

L'informatica forense è una disciplina che presenta una serie di caratteristiche particolari, che possono farla apparire instabile o fragile.

Un primo problema è la continua e rapida evoluzione delle tecnologie informatiche, sia a livello di hardware, che di software.^[Nell'ambito delle scienze naturali, i fenomeni naturali non cambiano, cambiano solo le teorie ed i modelli che gli scienziati sviluppano per spiegarli. Viceversa, nell'ambito dell'informatica forense, i supporti, sistemi, programmi e dati informatici sono in continua evoluzione.] Pertanto, i metodi di analisi tendono ad essere sempre innovativi, e nel tempo necessario per svolgere una *peer review* approfondita, potrebbero già essere diventati obsoleti.^[Il problema è aggravato dal fatto che il sistema operativo ed il software vengono spesso aggiornati in maniera automatica all'ultima versione, senza l'intervento dell'utente, per esigenze di sicurezza informatica. Pertanto, anche se i dati che sono stati acquisiti in un certo momento non varieranno nel tempo, la ricerca scientifica potrebbe non avere ancora a disposizione strumenti comprovati e maturi per analizzarli.]

Un altro problema è che l'attività di ricerca non è libera, ma è vincolata da vari tipi di limiti:

- Materiali: i supporti materiali su cui i dati sono memorizzati potrebbero non essere rimovibili^[È il classico caso degli smartphone, o di altri dispositivi creati per uno scopo particolare, come gli apparecchi elettromedicali.] o potrebbero usare interfacce proprietarie;^[In entrambi i casi, l'estrazione dei dati dal dispositivo potrebbe essere impossibile, o limitata.]
- Tecnici: anche laddove sia possibile acquisire tutti i dati da un dispositivo, è possibile che il software usato da quel dispositivo usi misure di protezione tecniche per rendere più difficile la sua analisi;^[Ad esempio, tecniche come la crittografia, *code obfuscation*, ecc., che complicano lo studio del funzionamento del software.]
- Relativi alla documentazione: il funzionamento dei programmi ed il formato dei dati spesso non sono documentati pubblicamente,^[La documentazione potrebbe essere fornita solo a sviluppatori di terze parti, ma solo a discrezione degli sviluppatori originali, e comunque con un vincolo di *NDA* (*non-disclosure agreement*, accordo di riservatezza), in modo che queste informazioni non possano essere condivise con il pubblico. Tuttavia, anche se questa documentazione viene fornita, potrebbe essere incompleta o inadeguata per i fini specifici delle investigazioni di informatica forense, che mirano ad accertare l'integrità (non-manomissione) dei dati, e ricostruire le dinamiche che hanno portato ad un certo assetto dei dati. È molto probabile che le specifiche tecniche dei file e protocolli siano documentati in dettaglio, ma è meno probabile che il funzionamento del sistema operativo e dei programmi (quali file aprono, modificano, creano od eliminano durante il loro funzionamento, come i file vengono modificati, a quali condizioni, in che formato&hellip;) siano oggetto di descrizione.] e pertanto devono essere ricostruiti con un lungo, dispendioso, e potenzialmente inaffidabile processo di tentativi ed errori;
- Legali: in ogni caso, istituti come il diritto d'autore, la disciplina relativa ai brevetti e ai segreti industriali, etc. possono porre dei limiti all'attività di ricerca scientifica.^[Ad esempio, possono limitare la possibilità di creare copie del software oggetto di studio, di rimuovere mezzi di protezione per studiare meglio il software, di re-implementare il funzionamento del software per creare uno strumento di analisi, possono giustificare il rifiuto di fornire informazioni sul funzionamento del software, etc.]

L'ultimo problema è la fragilità dei dati informatici: è difficile prevenire, rilevare o annullare la loro dispersione o modifica, che sia accidentale o intenzionale.

Per quanto riguarda le modifiche accidentali, la conservazione e trasmissione dei dati richiede sempre una modifica della realtà materiale,^[La modifica può anche essere di breve durata, o riguardare un'area limitata, ma deve comunque essere misurabile. Se così non fosse, i dati digitali sarebbero completamente immateriali e immaginari. Ad esempio, le modalità di trasmissione senza fili (Bluetooth, Wi-Fi, ecc.) hanno un raggio utile limitato, al di fuori del quale la trasmissione diventa impossibile, ed i dati che vengono trasmessi smettono di esistere se la trasmissione viene interrotta. Ancora, i dati nella memoria RAM sono memorizzati, non trasmessi, ma si disperdono appena il sistema viene spento.] e pertanto, qualsiasi problema nella realtà materiale si riflette sui dati:

- Il deterioramento^[Inteso come il processo naturale, inevitabile ed irreversibile per cui tutta la materia tende progressivamente verso il disordine.] del supporto materiale comporta la graduale perdita di funzionalità del supporto;^[Nell'ipotesi migliore, il sistema rileva la presenza di settori corrotti che sono diventati illeggibili, lo comunica all'utente, ed in alcuni casi, cerca di ripristinare i dati. Ad esempio, se si hanno due dischi configurati in modo da usare lo schema di archiviazione RAID 1, entrambi i dischi contengono una copia identica dei dati. Se un settore è corrotto su un disco, è possibile recuperare i dati dall'altro disco. Nei casi più gravi, il sistema non si accorge che un settore è corrotto, e restituisce un dato errato senza informare l'utente. Nel caso peggiore, l'intero supporto non viene più riconosciuto dal sistema. A quel punto, è necessario utilizzare tecniche particolarmente invasive per cercare di recuperare i dati, che richiedono lo smontaggio irreversibile del supporto materiale, ed in ogni caso, pongono problemi dal punto di vista della loro affidabilità.]
- Il malfunzionamento^[Inteso come un fenomeno estremamente raro da un punto di vista statistico, per cui un supporto non deteriorato si comporta in maniera erronea.] può dipendere da cause "naturali"^[Come i *bit flip* (inversione di singoli bit) dovuta a raggi cosmici. V. T. Long, *This Week in Glean: What Flips Your Bit?*, 2022, <https://web.archive.org/web/20220413132337/https://blog.mozilla.org/data/2022/04/13/this-week-in-glean-what-flips-your-bit/>.] o cause "meccaniche".^[Come gli *unrecoverable read errors* (errori di lettura irrimediabili) che sono dovuti al fatto che il supporto materiale è pur sempre un oggetto imperfetto, che può occasionalmente compiere errori. V. T. Pott, I. Thomson, *Flash banishes the spectre of the unrecoverable data error*, 2015, <https://web.archive.org/web/20200707202632/https://www.theregister.com/2015/05/07/flash_banishes_the_spectre_of_the_unrecoverable_data_error/>.]

Per quanto riguarda le modifiche intenzionali, in linea teorica, se è possibile entrare in possesso del supporto, è anche possibile modificare i suoi contenuti:

- La distruzione integrale di tutti i dati mediante sovrascrittura è considerata irreversibile;^[V. @Feenberg2013. Tradizionalmente si raccomandava l'uso di numerosi passaggi (v. @Gutmann1996), ma successivamente è stato dimostrato che è sufficiente un singolo passaggio, che imposta tutti i bit a zero (v. @Wolbe2018_ZeroFilledHardDrive).]
- La modifica arbitraria di contenuti specifici del disco^[Ad esempio, eliminare solo alcuni file, o modificare i loro contenuti.] è più complessa, e può essere rilevata mediante l'uso di varie tecniche.^[La semplice eliminazione di un file non rimuove immediatamente i suoi contenuti, ma li segna solo come spazio libero. Usando software specializzati (ad esempio, *PhotoRec*), è possibile esaminare le aree del supporto segnate per ricercare file cancellati. Se il file è stato sovrascritto prima di essere eliminato (ad esempio, con GNU *shred*, v. @GNUCoreutilsManual, sez. 11.6), è possibile che una copia dei contenuti del file possa essere trovata altrove. Ad esempio, se il file è un'immagine o un video, il sistema operativo spesso produce una *thumbnail* (anteprima) dei contenuti di quel file. Sovrascrivere il file non elimina automaticamente anche l'anteprima, che è salvata in maniera indipendente rispetto al file. Per quanto riguarda la modifica dei file, è necessario verificare se il sistema operativo o altre applicazioni tengono traccia dell'integrità dei file o delle operazioni compiute mediante *checksum* o *log files*. In questi casi, è possibile confrontare se il file corrisponde o meno a quanto ci si aspetta sulla base di questi valori di riferimento.]

Per cercare di impedire questo tipo di modifiche, si possono usare delle misure di sicurezza, che possono essere ricondotte a due grandi famiglie:

- Le misure di sicurezza software^[Ad esempio, il software che normalmente richiede la password per accedere all'account di un utente, o impedisce che l'utente attualmente autenticato possa visualizzare o modificare file di altri utenti, o file gestiti dal sistema operativo.] sono efficaci solo quando il sistema è attivo,^[Se il sistema è spento, non sono in esecuzione. L'unica eccezione è la *encryption-at-rest* (crittografia a riposo), dove i dati rimangono criptati (e quindi illeggibili a chiunque non conosca la chiave per decrittarli) anche quando il sistema è spento.] e possono essere aggirate con relativa facilità.^[Spesso il software presenta degli errori di programmazione che possono essere oggetto di *exploit* (sfruttati) per aggirare le misure di sicurezza.]
- Le misure di sicurezza hardware^[Ad esempio, il supporto si rifiuta di funzionare a meno che non venga inserita una password mediante dei pulsanti fisici, un *USB dongle*, etc.] sono sempre attive, e se implementate correttamente, sono pressoché impossibili da aggirare;^[Ad esempio, i dispositivi prodotti dalla Apple negli ultimi anni includono varie misure di sicurezza a livello hardware, che rendono difficile manomettere il sistema operativo, o decrittare i dati dell'utente. V. @Apple2022_PlatformSecurity, p. 7.]

Un'altra caratteristica dei dati informatici è il fatto che le modifiche non lasciano tracce. Nel caso in cui le misure di sicurezza vengono aggirate, ed i dati informatici vengono modificati, è impossibile risalire con certezza al loro stato precedente, e tutte le ricostruzioni sono al più ipotesi.^[Nel mondo materiale, è praticamente impossibile agire senza lasciare una qualche minima traccia, ma nel mondo digitale, i singoli bit sono già l'unità di memoria minima. Ad esempio, sovrascrivere un singolo bit trasforma la sequenza di caratteri "1966" in "1946" (v. @Gammarota2016, p. 62), ed è praticamente impossibile trovare tracce di questo cambiamento. I bit adiacenti sono rimasti inalterati, e il bit che è stato sovrascritto non mantiene traccia del suo valore precedente. Se quella data non occorre altrove, la modifica non può essere rilevata, e anche se occorresse altrove, sorgerebbe il problema di spiegare le incongruenze e capire quale sia la data autentica.]

## Informatica forense come scienza naturale

Date queste premesse, potrebbe sembrare che l'informatica forense sia una disciplina fragile ed instabile, tendenzialmente incapace di fornire elementi utili all'interno di un processo. Tuttavia, è proprio questa fragilità che giustifica l'uso di un approccio scientifico e rigoroso.

Il primo passo è determinare se l'informatica forense possa essere considerata una scienza forense.^[L'aggettivo "forense" nell'espressione "informatica forense" suggerisce la sua affinità con le altre scienze forensi, che possono essere legate sia alle scienze naturali (ad esempio, la medicina legale e la tossicologia forense sono strettamente legate alla biologia, la balistica forense è legata alla fisica), o alle scienze sociali (ad esempio, la criminologia e la psicologia).] L'informatica forense si appoggia all'informatica, che non è né una scienza sociale,^[L'informatica può essere usata dalle scienze sociali per analizzare grandi quantità di dati, ma interessa principalmente come strumento, non come scienza. Si pensi al settore della *data analytics*, che analizza enormi quantità di dati grezzi relativi ad utenti di siti internet per studiare, ed eventualmente manipolare, fenomeni sociali (ad esempio, a quali temi gli utenti sono interessati, e come incentivarli ad acquistare determinati prodotti), e la relativa regolazione da parte del diritto, che cerca di regolare l'utilizzazione dei dati personali resi disponibili dagli utenti su internet, con strumenti come la GDPR.] né una scienza naturale.^[L'oggetto dello studio dell'informatica è l'elaborazione automatica delle informazioni, e "cosa si può fare con l'informazione", e non l'informazione come "fenomeno naturale", e "come l'informazione esiste", che invece è oggetto di studio di altre discipline, come la fisica.]

L'informatica ha una natura puramente teorica, ed è analoga alla matematica. È difficile definirla una "scienza" in senso proprio, ma piuttosto, è un insieme di conoscenze organizzate che risultano utili per altre scienze.^[V. @Bilaniuk1996. In ultima analisi, tutte le scienze naturali sono fondate sulla matematica. Ad esempio, la sociologia si fonda sulla psicologia, che si fonda sulla biologia, che si fonda sulla chimica, che si fonda sulla fisica, che per ultima si fonda direttamente sulla matematica, che può essere definita la scienza più "pura", perché non studia né gli esseri umani, né la natura materiale, ma fenomeni completamente astratti. V. R. Munroe, *Purity*, n.d., <https://xkcd.com/435/>.]

Sia la matematica, sia l'informatica usano concetti astratti,^[Ad esempio, la matematica usa concetti come "numeri", "punti", "rette", e l'informatica usa concetti come "bit" e "byte", gli operatori booleani, le funzioni. In entrambi i casi, le discipline danno solo una definizione assiomatica di questi concetti, e non si preoccupano di studiare come rappresentarli nella realtà materiale.] che vengono combinati fra di loro per mezzo di ragionamenti deduttivi,^[Un teorema è un ragionamento logico che è sempre valido, e prescinde dall'uso di osservazioni empiriche per essere dimostrato. Ad esempio, gli *Elementi* di Euclide, ed il *lambda calculus* di Church sono esempi di sistemi di regole create con il metodo deduttivo. Viceversa, le scienze naturali usano un modello induttivo, e creano un sistema di regole sulla base dell'osservazione di numerosi fenomeni empirici.] e algoritmi.^[Gli algoritmi sono sequenze di istruzioni che non hanno un contenuto definitorio o conoscitivo, ma solamente imperativo. Un algoritmo spiega come manipolare delle informazioni per arrivare ad un certo risultato. Le scienze naturali cercano di definire e spiegare il funzionamento dei fenomeni naturali.]

Mentre è difficile affermare che la matematica e l'informatica siano "scienze", data la loro natura deduttiva, è possibile argomentare che l'informatica forense^[Intesa come l'applicazione dell'informatica per il trattamento dei dati ai fini processuali.] sia una scienza naturale a pieno titolo. 

In primo luogo i supporti materiali su cui i dati sono memorizzati sono soggetti ai fenomeni naturali, e lo studio delle scienze naturali permette di determinare le migliori modalità per il trattamento dei supporti materiali.^[Dato che qualsiasi danno al supporto materiale diventa anche un danno per i dati informatici in esso contenuti, l'informatica forense smette di avere una natura puramente astratta, e viene "contaminata" dalle scienze naturali.]

Ancora, il sistema operativo ed i programmi possono essere considerati un "fenomeno naturale", perché le loro modalità di funzionamento non sono immediatamente evidenti.

Se il software è proprietario, e non si ha accesso al codice sorgente, si possono usare le stesse tecniche usate dagli scienziati che studiano un fenomeno naturale:^[Per un esempio di un'opera che applica il metodo scientifico all'informatica forense, v. @Cinti2011.]

- Si interagisce con il software, e si documentano le operazioni svolte, ed i risultati osservati.^[È importante documentare in maniera dettagliata non solo le modalità d'uso del software, ma anche le modalità con cui è stato installato e configurato, che versione si sta usando, da dove è stato scaricato, ecc.]
- Si formulano delle ipotesi di leggi che descrivono il funzionamento del fenomeno;^[Ad esempio, "data la sequenza di azioni *X*, il programma produce i cambiamenti *Y*". La formulazione delle ipotesi è libera, e non segue schemi formali, ma è possibile formulare nuove ipotesi iterando su quelle già sviluppate. V. @Blachowicz2009, pp. 321--323.]
- Si sottopongono le ipotesi a verificazione mediante esperimenti, e si documentano i risultati;^[La fase di verificazione è particolarmente delicata. Il solo fatto che i risultati osservati confermano l'ipotesi oggetto di esame non è sufficiente a dimostrare che l'ipotesi sia valida, perché serve anche dimostrare che i risultati non siano dovuti a cause alternative (v. @Blachowicz2009, p. 325). È la fallacia logica di affermare il conseguente: "Se *A*, *B*; *B*; pertanto, *A*", ma questo ignora il fatto che *B* potrebbe avere altre cause oltre che *A*. Ad esempio, si potrebbe affermare: "Se nei programmi ci sono bug, si arresteranno in maniera inaspettata. Windows si è arrestato inaspettatamente, pertanto Windows deve avere un bug". Tuttavia, se Windows si arresta anche quando esegue istruzioni estremamente semplici, come impostare un valore a 0, si iniziano a sospettare altre cause per l'arresto inaspettato, tra cui l'instabilità dell'hardware dovuta ad *overclocking* (la sovralimentazione di un processore al fine di aumentare le prestazioni, al costo di sacrificare il suo corretto funzionamento). V. R. Chen, *There's an awful lot of overclocking out there*, 2005, <https://web.archive.org/web/20231003201601/https://devblogs.microsoft.com/oldnewthing/20050412-47/?p=35923>.]
- Le ipotesi e l'esperimento vengono raffinati, in modo da cercare di creare un esperimento controllato, un esperimento dove l'unico elemento che cambia è la variabile che viene studiata;^[Nell'informatica, si parla di *minimum reproducible example* (minimo esempio riproducibile). L'esperimento deve contenere la minima quantità di azioni strettamente necessarie per raggiungere il risultato, deve contenere gli eventuali dati da fornire in input, e si deve verificare che se eseguito più volte, produca sempre gli stessi risultati. V. Vercel.com, *https://web.archive.org/web/20220927020224/https://vercel.com/guides/creating-a-minimal-reproducible-example*, n.d., <https://web.archive.org/web/20220927020224/https://vercel.com/guides/creating-a-minimal-reproducible-example>.]
- L'esperimento viene condiviso con altri ricercatori, in modo da garantire che sia ripetibile,^[Ossia, altre persone possono svolgere le stesse azioni.] ed i risultati siano riproducibili;^[Ossia, svolgere le stesse azioni porta agli stessi risultati. La riproduzione dei risultati degli esperimenti è un momento tanto importante quanto la verificazione iniziale delle ipotesi, perché è una sorta di verificazione diffusa. Se un certo comportamento non può essere osservato con regolarità, non può formare la base di teorie scientifiche.]
- Eventualmente, si arriva alla creazione di una serie di massime di esperienza, di "leggi scientifiche" che sono state comprovate empiricamente, e formano una "teoria" sul funzionamento di quel programma.

Se il software è libero, ed è possible prendere visione del codice sorgente, e quindi sapere esattamente quali istruzioni sono eseguite dal programma, rimane comunque un margine di incertezza, perché I software possono contenere *bug* (errori di programmazione).^[Un bug è la situazione che si verifica quando leggendo il codice ci si aspetta il risultato *X*, ma eseguendolo si ottiene il risultato *Y*.]

I bug vengono studiati dai programmatori con tecniche di *debugging*, che sono pienamente ispirate al metodo scientifico.^[Un bug viene rilevato (osservazione), si documentano le azioni che lo causano (documentazione), si formula un ipotesi riguardo a quali istruzioni nel codice possano causare quel bug (formulazione di ipotesi), si apportano le modifiche necessarie al codice per vedere se il bug continua a presentarsi (verifica dell'ipotesi), e si continuano a formulare e verificare altre ipotesi fino a quando il bug viene corretto. È buona pratica documentare, dove possibile e ragionevole, la causa del bug, in modo da evitare una *regression* (situazione dove lo stesso bug che era stato già risolto si ripresenta nel futuro), ed evitare di commettere lo stesso errore in futuro in altre parti del codice.] Mentre i programmatori sono interessati a eliminare il bug, perché è un difetto del programma, l'informatica forense è interessata a comprendere il suo impatto sui dati.^[Dal punto di vista dell'informatica forense, un *bug* non è un difetto del programma oggetto di analisi, ma parte integrante del suo funzionamento.]

Un altro elemento da considerare è l'infinita riproducibilità dei dati informatici oggetto di analisi. A differenza dei fenomeni naturali, o delle prove materiali, è possibile duplicarli un numero infinito di volte, senza *generational loss* (perdita di qualità fra copie successive),^[Ad esempio, si pensi a come le fotocopie di fotocopie hanno una qualità minore rispetto ad una fotocopia dell'originale. I dati informatici sono soltanto delle sequenze di valori binari, ed è estremamente semplice creare delle copie, e confrontarle. Se le sequenze di bit sono identiche, i dati informatici sono indistinguibili ed equivalenti, e non è possibile distinguere fra l'originale e la copia.] ed è possibile verificare l'integrità della copia rispetto all'originale^[L'integrità della copia va verificata subito dopo la sua creazione, e periodicamente nel corso del tempo.] calcolando l'*hash* crittografico dei dati.^[In inglese, *to hash* significa "sminuzzare". Un algoritmo di hash "sminuzza" un file, nel senso che il file viene diviso letto come una serie di *blocks* ("blocchi", tranche), che vengono progressivamente ricombinati fra di loro per generare un *digest* (riassunto) dei dati originali, che ha una lunghezza fissa e breve (128 bit per MD5, 160 bit per SHA-1). La prima proprietà degli hash è che gli stessi dati in entrata producono sempre lo stesso hash in uscita. Si può verificare che due sequenze di bit sono identiche calcolando e confrontando il loro hash. La seconda proprietà degli hash è che cambiare anche un singolo bit nei dati in entrata cambierà (in media) la metà dei bit in uscita. Pertanto, anche la minima differenza fra due sequenze di bit produrrà hash completamente diversi. È una buona pratica usare almeno due hash, in modo da avere più valori di riferimento per verificare l'integrità dei dati.]

Pertanto, si può concludere che l'informatica forense non possa essere considerata completamente inaffidabile, perché può essere paragonata alle altre scienze naturali. Entrambe sono in continua evoluzione^[È impossibile arrestare il progresso tecnologico nell'informatica, o il progresso scientifico nelle altre scienze naturali. Da entrambi i lati, la conoscenza scientifica è in continuo cambiamento, perché cerca di creare modelli sempre più precisi.] ed entrambe usano la stessa metodologia.^[Pertanto, se si ritiene che le scienze naturali siano affidabili dal punto di vista epistemologico, analoghe considerazioni vanno fatte per l'informatica forense.]
